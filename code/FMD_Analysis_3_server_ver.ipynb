{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMD Analysis Ver3\n",
    "\n",
    "**在服务器中使用**\n",
    "***\n",
    "F->Fake News;\n",
    "\n",
    "M->Main Stream Media;\n",
    "\n",
    "D->Debunkers;\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*注：新冠疫情首批感染者出现在2019年12月，另外2023年5月5日，世界卫生组织宣布，新冠疫情不再构成“国际关注的突发公共卫生事件”。文件9_filtered.csv到27_filtered.csv包含从首批感染者出现开始，到世界卫生组织发表声明几个月之前的数据。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有文件合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef cat_file(file_num_list: list) -> pd.DataFrame:\\n\\n    df_ls = []\\n    for i in file_num_list:\\n        f = pd.read_csv(\"../csv_filtered/\" + str(i) + \"_filtered.csv\")\\n        df_ls.append(f)\\n        print(i)\\n    \\n    df_cat = pd.concat(df_ls, axis=0)\\n    df_cat.drop([\\'Unnamed: 0\\'], axis=1, inplace=True)\\n    return df_cat\\n\\n# 合并从第9到27号文件\\n# 文件内部的数据是从时间新到旧排序的，为了按时间顺序拼接，将list反转\\ndf = cat_file(list(range(9, 27+1))[::-1])\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将指定的X_filtered.csv文件合并\n",
    "'''\n",
    "def cat_file(file_num_list: list) -> pd.DataFrame:\n",
    "\n",
    "    df_ls = []\n",
    "    for i in file_num_list:\n",
    "        f = pd.read_csv(\"../csv_filtered/\" + str(i) + \"_filtered.csv\")\n",
    "        df_ls.append(f)\n",
    "        print(i)\n",
    "    \n",
    "    df_cat = pd.concat(df_ls, axis=0)\n",
    "    df_cat.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    return df_cat\n",
    "\n",
    "# 合并从第9到27号文件\n",
    "# 文件内部的数据是从时间新到旧排序的，为了按时间顺序拼接，将list反转\n",
    "df = cat_file(list(range(9, 27+1))[::-1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存文件\n",
    "#df.to_csv(\"data/full_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3808339 entries, 0 to 3808338\n",
      "Data columns (total 83 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   id                                     int64  \n",
      " 1   conversation_id                        int64  \n",
      " 2   referenced_tweets.replied_to.id        float64\n",
      " 3   referenced_tweets.retweeted.id         float64\n",
      " 4   referenced_tweets.quoted.id            float64\n",
      " 5   author_id                              int64  \n",
      " 6   in_reply_to_user_id                    float64\n",
      " 7   in_reply_to_username                   object \n",
      " 8   retweeted_user_id                      float64\n",
      " 9   retweeted_username                     object \n",
      " 10  quoted_user_id                         float64\n",
      " 11  quoted_username                        object \n",
      " 12  created_at                             object \n",
      " 13  text                                   object \n",
      " 14  lang                                   object \n",
      " 15  source                                 float64\n",
      " 16  public_metrics.impression_count        int64  \n",
      " 17  public_metrics.reply_count             int64  \n",
      " 18  public_metrics.retweet_count           int64  \n",
      " 19  public_metrics.quote_count             int64  \n",
      " 20  public_metrics.like_count              int64  \n",
      " 21  reply_settings                         object \n",
      " 22  edit_history_tweet_ids                 object \n",
      " 23  edit_controls.edits_remaining          float64\n",
      " 24  edit_controls.editable_until           object \n",
      " 25  edit_controls.is_edit_eligible         object \n",
      " 26  possibly_sensitive                     bool   \n",
      " 27  withheld.scope                         object \n",
      " 28  withheld.copyright                     object \n",
      " 29  withheld.country_codes                 object \n",
      " 30  entities.annotations                   object \n",
      " 31  entities.cashtags                      object \n",
      " 32  entities.hashtags                      object \n",
      " 33  entities.mentions                      object \n",
      " 34  entities.urls                          object \n",
      " 35  context_annotations                    object \n",
      " 36  attachments.media                      object \n",
      " 37  attachments.media_keys                 object \n",
      " 38  attachments.poll.duration_minutes      float64\n",
      " 39  attachments.poll.end_datetime          object \n",
      " 40  attachments.poll.id                    float64\n",
      " 41  attachments.poll.options               object \n",
      " 42  attachments.poll.voting_status         object \n",
      " 43  attachments.poll_ids                   object \n",
      " 44  author.id                              int64  \n",
      " 45  author.created_at                      object \n",
      " 46  author.username                        object \n",
      " 47  author.name                            object \n",
      " 48  author.description                     object \n",
      " 49  author.entities.description.cashtags   object \n",
      " 50  author.entities.description.hashtags   object \n",
      " 51  author.entities.description.mentions   object \n",
      " 52  author.entities.description.urls       object \n",
      " 53  author.entities.url.urls               object \n",
      " 54  author.url                             object \n",
      " 55  author.location                        object \n",
      " 56  author.pinned_tweet_id                 float64\n",
      " 57  author.profile_image_url               object \n",
      " 58  author.protected                       bool   \n",
      " 59  author.public_metrics.followers_count  int64  \n",
      " 60  author.public_metrics.following_count  int64  \n",
      " 61  author.public_metrics.listed_count     float64\n",
      " 62  author.public_metrics.tweet_count      int64  \n",
      " 63  author.verified                        bool   \n",
      " 64  author.verified_type                   float64\n",
      " 65  author.withheld.scope                  object \n",
      " 66  author.withheld.copyright              float64\n",
      " 67  author.withheld.country_codes          object \n",
      " 68  geo.coordinates.coordinates            object \n",
      " 69  geo.coordinates.type                   object \n",
      " 70  geo.country                            object \n",
      " 71  geo.country_code                       object \n",
      " 72  geo.full_name                          object \n",
      " 73  geo.geo.bbox                           object \n",
      " 74  geo.geo.type                           object \n",
      " 75  geo.id                                 object \n",
      " 76  geo.name                               object \n",
      " 77  geo.place_id                           object \n",
      " 78  geo.place_type                         object \n",
      " 79  matching_rules                         float64\n",
      " 80  __twarc.retrieved_at                   object \n",
      " 81  __twarc.url                            object \n",
      " 82  __twarc.version                        object \n",
      "dtypes: bool(3), float64(15), int64(12), object(53)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通用户列表：将follower数小于500的用户视为普通用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_normal_user_list(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 将df的列名转换成字典：{col_index: col_key}\n",
    "    cols = dict(enumerate(df.columns))\n",
    "    # 调换键和值：{col_key: col_index}\n",
    "    swapped_cols = {v:k for k,v in cols.items()}\n",
    "    # 丢弃不需要的列\n",
    "    cols_drop = list(range(0, 1+swapped_cols['withheld.country_codes'])) + \\\n",
    "            list(range(swapped_cols['context_annotations'], 1+swapped_cols['attachments.poll_ids'])) + \\\n",
    "            list(range(swapped_cols['author.withheld.country_codes'], len(swapped_cols)))\n",
    "    cols_drop = [cols[i] for i in cols_drop]\n",
    "    df_drop_cols = df.drop(cols_drop, axis=1)\n",
    "    # 在'author.username'去重，得到所有用户的列表\n",
    "    user_all = df_drop_cols.drop_duplicates(subset=['author.username'], keep='first')\n",
    "    # 丢弃follower达到500的用户\n",
    "    idx_500 = {i for i in user_all.index if user_all['author.public_metrics.followers_count'][i] >= 500}\n",
    "    return user_all.drop(idx_500, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_norm = gen_normal_user_list(df)\n",
    "# user_norm.to_csv(\"data/user_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 824093 entries, 0 to 824092\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   entities.annotations                   753527 non-null  object \n",
      " 1   entities.cashtags                      317 non-null     object \n",
      " 2   entities.hashtags                      382086 non-null  object \n",
      " 3   entities.mentions                      241700 non-null  object \n",
      " 4   entities.urls                          594518 non-null  object \n",
      " 5   author.id                              824093 non-null  int64  \n",
      " 6   author.created_at                      824093 non-null  object \n",
      " 7   author.username                        824093 non-null  object \n",
      " 8   author.name                            823962 non-null  object \n",
      " 9   author.description                     587239 non-null  object \n",
      " 10  author.entities.description.cashtags   569 non-null     object \n",
      " 11  author.entities.description.hashtags   62123 non-null   object \n",
      " 12  author.entities.description.mentions   38207 non-null   object \n",
      " 13  author.entities.description.urls       16368 non-null   object \n",
      " 14  author.entities.url.urls               116973 non-null  object \n",
      " 15  author.url                             116973 non-null  object \n",
      " 16  author.location                        475171 non-null  object \n",
      " 17  author.pinned_tweet_id                 204405 non-null  float64\n",
      " 18  author.profile_image_url               824008 non-null  object \n",
      " 19  author.protected                       824093 non-null  bool   \n",
      " 20  author.public_metrics.followers_count  824093 non-null  int64  \n",
      " 21  author.public_metrics.following_count  824093 non-null  int64  \n",
      " 22  author.public_metrics.listed_count     824093 non-null  float64\n",
      " 23  author.public_metrics.tweet_count      824093 non-null  int64  \n",
      " 24  author.verified                        824093 non-null  bool   \n",
      " 25  author.verified_type                   0 non-null       float64\n",
      " 26  author.withheld.scope                  0 non-null       float64\n",
      " 27  author.withheld.copyright              0 non-null       float64\n",
      "dtypes: bool(2), float64(5), int64(4), object(17)\n",
      "memory usage: 165.0+ MB\n"
     ]
    }
   ],
   "source": [
    "user_norm = pd.read_csv(\"data/user_norm.csv\")\n",
    "user_norm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取媒体列表：虚假信息媒体、主流媒体、辟谣媒体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1481 entries, 0 to 1480\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Domain                 1481 non-null   object \n",
      " 1   Site Rank              1481 non-null   int64  \n",
      " 2   Year online            1435 non-null   float64\n",
      " 3   Name                   1481 non-null   object \n",
      " 4   Media Bias/Fact Check  1481 non-null   object \n",
      " 5   MBFC Fact              1480 non-null   object \n",
      " 6   MBFC Bias              1481 non-null   object \n",
      " 7   MisinfoMe              1339 non-null   float64\n",
      " 8   Wikipedia              748 non-null    object \n",
      " 9   Lang                   1480 non-null   object \n",
      " 10  URL                    1481 non-null   object \n",
      " 11  MBFC cred              1481 non-null   object \n",
      " 12  Unnamed: 12            0 non-null      float64\n",
      " 13  Unnamed: 13            0 non-null      float64\n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 162.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# 虚假信息媒体（fake news）\n",
    "fn_df = pd.read_csv(\"data/FakeNewsDomain_from_iffy.news_23.09.06.csv\")\n",
    "fn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   site_name       27 non-null     object\n",
      " 1   site            27 non-null     object\n",
      " 2   twitter_handle  27 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 776.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 主流媒体（mainstream）\n",
    "ms_df = pd.read_csv(\"data/high_credibility_websites_CoVaxxy.csv\")\n",
    "ms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45 entries, 0 to 44\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   name             45 non-null     object\n",
      " 1   domain           41 non-null     object\n",
      " 2   twitter_account  33 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 辟谣媒体（debunking）\n",
    "db_df = pd.read_csv(\"data/(Merge)debunking_fact-checking_sites.csv\")\n",
    "db_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计数每名普通用户分享三种媒体的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每种媒体的数据建好一个空栏\n",
    "user_norm['fake_news_share'] = ''\n",
    "user_norm['mainstream_share'] = ''\n",
    "user_norm['debunking_share'] = ''\n",
    "\n",
    "# 三种媒体的网站域名和推特账号\n",
    "fn_domain = set(fn_df['Domain'].dropna())\n",
    "\n",
    "ms_domain = set(ms_df['site'].dropna())\n",
    "ms_account = set(ms_df['twitter_handle'].dropna())\n",
    "\n",
    "db_domain = set(db_df['domain'].dropna())\n",
    "db_account = set(db_df['twitter_account'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin = 700000\n",
      "i = 701000, n = 701000\n"
     ]
    }
   ],
   "source": [
    "# 使用numpy array加快查找速度\n",
    "df_author = np.array(df['author.username'])\n",
    "n = 70 * 10000\n",
    "skip = 0\n",
    "begin = 0\n",
    "end = 0\n",
    "\n",
    "for i in user_norm.index:\n",
    "    # 跳过前n个用户\n",
    "    if skip < n:\n",
    "        skip += 1\n",
    "        continue\n",
    "    # 挑出i号用户发过的所有帖子的下标\n",
    "    indexes = np.argwhere(df_author == user_norm['author.username'][i]).flatten().tolist()\n",
    "    # 计数虚假信息媒体推文\n",
    "    user_norm['fake_news_share'][i] = \\\n",
    "        ( \\\n",
    "            {r for r in indexes if re.search('|'.join(fn_domain), string=df['text'][r])} \\\n",
    "        ).__len__()\n",
    "    # 计数主流媒体推文\n",
    "    user_norm['mainstream_share'][i] = \\\n",
    "        ( \\\n",
    "            {r for r in indexes if re.search('|'.join(ms_domain), string=df['text'][r])} \\\n",
    "            #+ {s for s in indexes if str(df['quoted_username'][s]) in ms_account} \\\n",
    "            #+ {t for t in indexes if str(df['retweeted_username'][t]) in ms_account} \\\n",
    "        ).__len__()\n",
    "    # 计数辟谣媒体推文\n",
    "    user_norm['debunking_share'][i] = \\\n",
    "        ( \\\n",
    "            {r for r in indexes if re.search('|'.join(db_domain), string=df['text'][r])} \\\n",
    "            #+ {s for s in indexes if str(df['quoted_username'][s]) in db_account} \\\n",
    "            #+ {t for t in indexes if str(df['retweeted_username'][t]) in db_account} \\\n",
    "        ).__len__()\n",
    "    # 暂存数据\n",
    "        # 开始计数工作，并记录开始的用户下标\n",
    "    if skip == n:\n",
    "        begin = i\n",
    "        print(\"begin = %d\" % (begin))\n",
    "        skip = np.inf\n",
    "        continue\n",
    "        # 每隔10000用户保存一次\n",
    "    n += 1\n",
    "    if (n % 1000) == 0:\n",
    "        print(\"i = %d, n = %d\" % (i, n))\n",
    "        if (n % 10000) == 0:\n",
    "            end = i\n",
    "            print(\"package = %d, begin = %d, end = %d\" % (n // 10000, begin, end))\n",
    "            save = user_norm[:][begin : end]\n",
    "            save.to_csv(\"TmpOutPut/\" + str(n // 10000) + \"_user.csv\")\n",
    "            begin = i\n",
    "else:\n",
    "    end = -1\n",
    "    save = user_norm[:][begin : end]\n",
    "    save.to_csv(\"TmpOutPut/\" + str(n // 10000 + 1) + \"_user.csv\")\n",
    "    print(n // 10000 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算“假新闻偏信分数”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义“假新闻偏信分数”为：\n",
    "\n",
    "fnbs = (fns - mss - dbs) / (fns + mss + dbs + 0.001)\n",
    "\n",
    "fnbs: fake_news_believe_score\n",
    "\n",
    "fns: fake_news_share\n",
    "\n",
    "mss: mainstream_share\n",
    "\n",
    "dbs: debunking_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并多个X_user.csv文件\n",
    "def cat_csv_files(file_name_list: list, output_file_name: str) -> None:\n",
    "    # 把文件加进一个列表\n",
    "    df_ls = []\n",
    "    for s in file_name_list:\n",
    "        df = pd.read_csv(s)\n",
    "        df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "        df_ls.append(df)\n",
    "    # 合并\n",
    "    df_cat = pd.concat(df_ls, axis=0)\n",
    "    df_cat.to_csv(output_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并多个X_user.csv文件\n",
    "file_name_list = [\"TmpOutPut/\" + str(i) + \"_user.csv\" for i in range(1, 83+1)][::-1]\n",
    "#cat_csv_files(file_name_list, \"data/normal_user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 824092 entries, 0 to 824091\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   entities.annotations                   753527 non-null  object \n",
      " 1   entities.cashtags                      317 non-null     object \n",
      " 2   entities.hashtags                      382086 non-null  object \n",
      " 3   entities.mentions                      241700 non-null  object \n",
      " 4   entities.urls                          594518 non-null  object \n",
      " 5   author.id                              824092 non-null  int64  \n",
      " 6   author.created_at                      824092 non-null  object \n",
      " 7   author.username                        824092 non-null  object \n",
      " 8   author.name                            823961 non-null  object \n",
      " 9   author.description                     587238 non-null  object \n",
      " 10  author.entities.description.cashtags   569 non-null     object \n",
      " 11  author.entities.description.hashtags   62123 non-null   object \n",
      " 12  author.entities.description.mentions   38207 non-null   object \n",
      " 13  author.entities.description.urls       16368 non-null   object \n",
      " 14  author.entities.url.urls               116973 non-null  object \n",
      " 15  author.url                             116973 non-null  object \n",
      " 16  author.location                        475170 non-null  object \n",
      " 17  author.pinned_tweet_id                 204405 non-null  float64\n",
      " 18  author.profile_image_url               824007 non-null  object \n",
      " 19  author.protected                       824092 non-null  bool   \n",
      " 20  author.public_metrics.followers_count  824092 non-null  int64  \n",
      " 21  author.public_metrics.following_count  824092 non-null  int64  \n",
      " 22  author.public_metrics.listed_count     824092 non-null  float64\n",
      " 23  author.public_metrics.tweet_count      824092 non-null  int64  \n",
      " 24  author.verified                        824092 non-null  bool   \n",
      " 25  author.verified_type                   0 non-null       float64\n",
      " 26  author.withheld.scope                  0 non-null       float64\n",
      " 27  author.withheld.copyright              0 non-null       float64\n",
      " 28  fake_news_share                        824092 non-null  int64  \n",
      " 29  mainstream_share                       824092 non-null  int64  \n",
      " 30  debunking_share                        824092 non-null  int64  \n",
      "dtypes: bool(2), float64(5), int64(7), object(17)\n",
      "memory usage: 183.9+ MB\n"
     ]
    }
   ],
   "source": [
    "user_norm = pd.read_csv(\"data/normal_user.csv\")\n",
    "user_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n",
      "374000\n",
      "375000\n",
      "376000\n",
      "377000\n",
      "378000\n",
      "379000\n",
      "380000\n",
      "381000\n",
      "382000\n",
      "383000\n",
      "384000\n",
      "385000\n",
      "386000\n",
      "387000\n",
      "388000\n",
      "389000\n",
      "390000\n",
      "391000\n",
      "392000\n",
      "393000\n",
      "394000\n",
      "395000\n",
      "396000\n",
      "397000\n",
      "398000\n",
      "399000\n",
      "400000\n",
      "401000\n",
      "402000\n",
      "403000\n",
      "404000\n",
      "405000\n",
      "406000\n",
      "407000\n",
      "408000\n",
      "409000\n",
      "410000\n",
      "411000\n",
      "412000\n",
      "413000\n",
      "414000\n",
      "415000\n",
      "416000\n",
      "417000\n",
      "418000\n",
      "419000\n",
      "420000\n",
      "421000\n",
      "422000\n",
      "423000\n",
      "424000\n",
      "425000\n",
      "426000\n",
      "427000\n",
      "428000\n",
      "429000\n",
      "430000\n",
      "431000\n",
      "432000\n",
      "433000\n",
      "434000\n",
      "435000\n",
      "436000\n",
      "437000\n",
      "438000\n",
      "439000\n",
      "440000\n",
      "441000\n",
      "442000\n",
      "443000\n",
      "444000\n",
      "445000\n",
      "446000\n",
      "447000\n",
      "448000\n",
      "449000\n",
      "450000\n",
      "451000\n",
      "452000\n",
      "453000\n",
      "454000\n",
      "455000\n",
      "456000\n",
      "457000\n",
      "458000\n",
      "459000\n",
      "460000\n",
      "461000\n",
      "462000\n",
      "463000\n",
      "464000\n",
      "465000\n",
      "466000\n",
      "467000\n",
      "468000\n",
      "469000\n",
      "470000\n",
      "471000\n",
      "472000\n",
      "473000\n",
      "474000\n",
      "475000\n",
      "476000\n",
      "477000\n",
      "478000\n",
      "479000\n",
      "480000\n",
      "481000\n",
      "482000\n",
      "483000\n",
      "484000\n",
      "485000\n",
      "486000\n",
      "487000\n",
      "488000\n",
      "489000\n",
      "490000\n",
      "491000\n",
      "492000\n",
      "493000\n",
      "494000\n",
      "495000\n",
      "496000\n",
      "497000\n",
      "498000\n",
      "499000\n",
      "500000\n",
      "501000\n",
      "502000\n",
      "503000\n",
      "504000\n",
      "505000\n",
      "506000\n",
      "507000\n",
      "508000\n",
      "509000\n",
      "510000\n",
      "511000\n",
      "512000\n",
      "513000\n",
      "514000\n",
      "515000\n",
      "516000\n",
      "517000\n",
      "518000\n",
      "519000\n",
      "520000\n",
      "521000\n",
      "522000\n",
      "523000\n",
      "524000\n",
      "525000\n",
      "526000\n",
      "527000\n",
      "528000\n",
      "529000\n",
      "530000\n",
      "531000\n",
      "532000\n",
      "533000\n",
      "534000\n",
      "535000\n",
      "536000\n",
      "537000\n",
      "538000\n",
      "539000\n",
      "540000\n",
      "541000\n",
      "542000\n",
      "543000\n",
      "544000\n",
      "545000\n",
      "546000\n",
      "547000\n",
      "548000\n",
      "549000\n",
      "550000\n",
      "551000\n",
      "552000\n",
      "553000\n",
      "554000\n",
      "555000\n",
      "556000\n",
      "557000\n",
      "558000\n",
      "559000\n",
      "560000\n",
      "561000\n",
      "562000\n",
      "563000\n",
      "564000\n",
      "565000\n",
      "566000\n",
      "567000\n",
      "568000\n",
      "569000\n",
      "570000\n",
      "571000\n",
      "572000\n",
      "573000\n",
      "574000\n",
      "575000\n",
      "576000\n",
      "577000\n",
      "578000\n",
      "579000\n",
      "580000\n",
      "581000\n",
      "582000\n",
      "583000\n",
      "584000\n",
      "585000\n",
      "586000\n",
      "587000\n",
      "588000\n",
      "589000\n",
      "590000\n",
      "591000\n",
      "592000\n",
      "593000\n",
      "594000\n",
      "595000\n",
      "596000\n",
      "597000\n",
      "598000\n",
      "599000\n",
      "600000\n",
      "601000\n",
      "602000\n",
      "603000\n",
      "604000\n",
      "605000\n",
      "606000\n",
      "607000\n",
      "608000\n",
      "609000\n",
      "610000\n",
      "611000\n",
      "612000\n",
      "613000\n",
      "614000\n",
      "615000\n",
      "616000\n",
      "617000\n",
      "618000\n",
      "619000\n",
      "620000\n",
      "621000\n",
      "622000\n",
      "623000\n",
      "624000\n",
      "625000\n",
      "626000\n",
      "627000\n",
      "628000\n",
      "629000\n",
      "630000\n",
      "631000\n",
      "632000\n",
      "633000\n",
      "634000\n",
      "635000\n",
      "636000\n",
      "637000\n",
      "638000\n",
      "639000\n",
      "640000\n",
      "641000\n",
      "642000\n",
      "643000\n",
      "644000\n",
      "645000\n",
      "646000\n",
      "647000\n",
      "648000\n",
      "649000\n",
      "650000\n",
      "651000\n",
      "652000\n",
      "653000\n",
      "654000\n",
      "655000\n",
      "656000\n",
      "657000\n",
      "658000\n",
      "659000\n",
      "660000\n",
      "661000\n",
      "662000\n",
      "663000\n",
      "664000\n",
      "665000\n",
      "666000\n",
      "667000\n",
      "668000\n",
      "669000\n",
      "670000\n",
      "671000\n",
      "672000\n",
      "673000\n",
      "674000\n",
      "675000\n",
      "676000\n",
      "677000\n",
      "678000\n",
      "679000\n",
      "680000\n",
      "681000\n",
      "682000\n",
      "683000\n",
      "684000\n",
      "685000\n",
      "686000\n",
      "687000\n",
      "688000\n",
      "689000\n",
      "690000\n",
      "691000\n",
      "692000\n",
      "693000\n",
      "694000\n",
      "695000\n",
      "696000\n",
      "697000\n",
      "698000\n",
      "699000\n",
      "700000\n",
      "701000\n",
      "702000\n",
      "703000\n",
      "704000\n",
      "705000\n",
      "706000\n",
      "707000\n",
      "708000\n",
      "709000\n",
      "710000\n",
      "711000\n",
      "712000\n",
      "713000\n",
      "714000\n",
      "715000\n",
      "716000\n",
      "717000\n",
      "718000\n",
      "719000\n",
      "720000\n",
      "721000\n",
      "722000\n",
      "723000\n",
      "724000\n",
      "725000\n",
      "726000\n",
      "727000\n",
      "728000\n",
      "729000\n",
      "730000\n",
      "731000\n",
      "732000\n",
      "733000\n",
      "734000\n",
      "735000\n",
      "736000\n",
      "737000\n",
      "738000\n",
      "739000\n",
      "740000\n",
      "741000\n",
      "742000\n",
      "743000\n",
      "744000\n",
      "745000\n",
      "746000\n",
      "747000\n",
      "748000\n",
      "749000\n",
      "750000\n",
      "751000\n",
      "752000\n",
      "753000\n",
      "754000\n",
      "755000\n",
      "756000\n",
      "757000\n",
      "758000\n",
      "759000\n",
      "760000\n",
      "761000\n",
      "762000\n",
      "763000\n",
      "764000\n",
      "765000\n",
      "766000\n",
      "767000\n",
      "768000\n",
      "769000\n",
      "770000\n",
      "771000\n",
      "772000\n",
      "773000\n",
      "774000\n",
      "775000\n",
      "776000\n",
      "777000\n",
      "778000\n",
      "779000\n",
      "780000\n",
      "781000\n",
      "782000\n",
      "783000\n",
      "784000\n",
      "785000\n",
      "786000\n",
      "787000\n",
      "788000\n",
      "789000\n",
      "790000\n",
      "791000\n",
      "792000\n",
      "793000\n",
      "794000\n",
      "795000\n",
      "796000\n",
      "797000\n",
      "798000\n",
      "799000\n",
      "800000\n",
      "801000\n",
      "802000\n",
      "803000\n",
      "804000\n",
      "805000\n",
      "806000\n",
      "807000\n",
      "808000\n",
      "809000\n",
      "810000\n",
      "811000\n",
      "812000\n",
      "813000\n",
      "814000\n",
      "815000\n",
      "816000\n",
      "817000\n",
      "818000\n",
      "819000\n",
      "820000\n",
      "821000\n",
      "822000\n",
      "823000\n",
      "824000\n"
     ]
    }
   ],
   "source": [
    "# 计算“假新闻偏信分数”\n",
    "#'''\n",
    "user_norm['fake_news_believe_score'] = ''\n",
    "b = 0.001\n",
    "\n",
    "n = 0\n",
    "for i in user_norm.index:\n",
    "    user_norm['fake_news_believe_score'][i] = \\\n",
    "        (user_norm['fake_news_share'][i] - user_norm['mainstream_share'][i] - user_norm['debunking_share'][i]) / \\\n",
    "        (user_norm['fake_news_share'][i] + user_norm['mainstream_share'][i] + user_norm['debunking_share'][i] + b)\n",
    "    n += 1\n",
    "    if n % 1000 == 0:\n",
    "        print(n)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 823325 351\n"
     ]
    }
   ],
   "source": [
    "# 统计“假新闻偏信分数”为正值、零值和负值的用户有多少\n",
    "#'''\n",
    "score_z = [i for i in user_norm.index if user_norm['fake_news_believe_score'][i] == 0].__len__()\n",
    "score_p = [i for i in user_norm.index if user_norm['fake_news_believe_score'][i] > 0].__len__()\n",
    "score_n = [i for i in user_norm.index if user_norm['fake_news_believe_score'][i] < 0].__len__()\n",
    "\n",
    "print(score_p, score_z, score_n)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424 192 167\n"
     ]
    }
   ],
   "source": [
    "r = [i for i in user_norm.index if user_norm['fake_news_share'][i] > 0].__len__()\n",
    "s = [i for i in user_norm.index if user_norm['mainstream_share'][i] > 0].__len__()\n",
    "t = [i for i in user_norm.index if user_norm['debunking_share'][i] > 0].__len__()\n",
    "print(r, s, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
