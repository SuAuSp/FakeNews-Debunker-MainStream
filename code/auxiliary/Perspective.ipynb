{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0229ea4",
   "metadata": {},
   "source": [
    "# 使用Perspective API分析文本毒性\n",
    "\n",
    "国外服务器或开代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2459f760-8dc4-479c-9e83-6e9a6ac93639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from joblib import load, dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 输出DataFrame时显示所有的列\n",
    "pd.set_option('display.max_columns', None)\n",
    "# 输出DataFrame时每行显示完整的内容\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d69e0c8-9cc4-4caf-a7ab-275bd24e1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 385956 entries, 0 to 385955\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   author.username  385956 non-null  object\n",
      " 1   text             385955 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# 取用户推文数据\n",
    "user_texts = pd.read_csv(\"data/user_texts[restrict=3media+retweet][topic=POTUS2020].csv\")\n",
    "user_texts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656331d8-06e8-41d3-a246-5aec79d6ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问API的函数体\n",
    "from googleapiclient import discovery\n",
    "\n",
    "def perspective_analyze(text):\n",
    "\n",
    "    API_KEY = 'AIzaSyAPlZbUYD2pYxmz_CsDPUe5vNIQFiGlxS0'\n",
    "\n",
    "    client = discovery.build(\n",
    "        \"commentanalyzer\",\n",
    "        \"v1alpha1\",\n",
    "        developerKey=API_KEY,\n",
    "        discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "        static_discovery=False,\n",
    "    )\n",
    "\n",
    "    analyze_request = {\n",
    "        'comment': {'text': text},\n",
    "        'requestedAttributes': {\n",
    "            'TOXICITY': {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return client.comments().analyze(body=analyze_request).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628ff0d",
   "metadata": {},
   "source": [
    "### 并行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f066ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49b0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def analyze_text(x):\n",
    "    try:\n",
    "        return perspective_analyze(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parallel_analyze(data, func, n_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        results = list(executor.map(func, data))\n",
    "    return results\n",
    "\n",
    "# 使用方法\n",
    "# results = parallel_analyse(list(df_url.iloc[i:i+chunk, :]['url']), analyse, n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始转换短URL\n",
    "begin = 0   # 开始的位置\n",
    "chunk = 500   # 分批处理，每批的数量\n",
    "chunk_10 = chunk * 10   # 每10批输出一次进度\n",
    "df['perspective_api_results'] = ''\n",
    "result_file = \"data/perspective_api_results[restrict=3media+retweet][topic=POTUS2020].csv\"\n",
    "\n",
    "for i in range(begin, df.shape[0], chunk): # df.shape[0]\n",
    "    tmp = parallel_analyze(list(df.loc[i:i+chunk, :]['text']), analyze_text, n_workers=4)   # 线程数量\n",
    "    df.loc[i:i+chunk, ['perspective_api_results']] = tmp\n",
    "    df.to_csv(result_file, index=False)\n",
    "    print(i, end=' ')\n",
    "    if (i % chunk_10) == 0:\n",
    "        print('\\n', end='')\n",
    "\n",
    "df.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860420e0",
   "metadata": {},
   "source": [
    "### 串行处理（一般用不到）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e063e4b-843a-43cc-9db9-a3bd99290899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理一半\n",
    "df = user_texts\n",
    "df.loc[:, ['author.username','perspective_api_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用API分析\n",
    "chunk_size = 100    # 每处理100个数据保存一次文件\n",
    "results_file = \"data/1-user_texts_with_perspective_api_results[restrict=retweet+3media][topic=POTUS2020].csv\"\n",
    "df['perspective_api_results'] = ''\n",
    "error_count = 0\n",
    "for i in df.index:\n",
    "    try:\n",
    "        df['perspective_api_results'][i] = perspective_analyze(df['text'][i])\n",
    "    except:\n",
    "        error_count += 1\n",
    "    if i != 0 and i % chunk_size == 0:\n",
    "        print(f\"number={i}, error_count={error_count}\")\n",
    "        df.to_csv(results_file, index=False)\n",
    "\n",
    "# 保存文件\n",
    "df.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理分析结果（用不到）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87293 entries, 0 to 87292\n",
      "Data columns (total 3 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   author.username          87293 non-null  object\n",
      " 1   text                     87293 non-null  object\n",
      " 2   perspective_api_results  87285 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "res = pd.read_csv(result_file)\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sample(8).loc[:, ['perspective_api_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将JSON展开的函数\n",
    "def json_to_df(x):\n",
    "    # JSON变成DataFrame\n",
    "    # x为待处理的JSON字符串\n",
    "    x = re.sub(pattern=\"'\", repl='\"', string=x) # 把单引号换成双引号，因为单引号在JSON中没有意义\n",
    "    dff = pd.json_normalize(json.loads(x))\n",
    "    # 消除列表，把列表元素拿出来\n",
    "    dff.loc[0, ['languages']] = dff['languages'][0]\n",
    "    dff.loc[0, ['detectedLanguages']] = dff['detectedLanguages'][0]\n",
    "    dff.loc[0, ['attributeScores.TOXICITY.spanScores']] = dff['attributeScores.TOXICITY.spanScores'][0]\n",
    "    # 处理JSON的嵌套结构\n",
    "    dff_normalized = pd.json_normalize(dff['attributeScores.TOXICITY.spanScores'])\n",
    "    dff_normalized\n",
    "    # 嵌套结构处理结果和原DataFrame合并\n",
    "    dff = pd.concat([dff, dff_normalized], axis=1).drop(['attributeScores.TOXICITY.spanScores'], axis=1)\n",
    "    # 重命名列\n",
    "    dff.columns = ['languages','detectedLanguages',\n",
    "                    'TOXICITY.summaryScore.value','TOXICITY.summaryScore.type',\n",
    "                    'TOXICITY.spanScore.begin','TOXICITY.spanScore.end',\n",
    "                    'TOXICITY.spanScore.value','TOXICITY.spanScore.type']\n",
    "    return dff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
